{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f43941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc166604",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = np.load(\"./checkpoints/extracted_features_minmax.npy\")\n",
    "labels = np.load(\"./checkpoints/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37aea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,test_X,train_y,test_y = train_test_split(extracted_features,labels,test_size=0.1,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17518905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53, 100), (6, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa082cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FeatureDataset(train_X,train_y)\n",
    "test_dataset = FeatureDataset(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff54294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(666)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=6,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf4875",
   "metadata": {},
   "source": [
    "# model 调用和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7af7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d029ab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6722, -0.7145],\n",
       "        [-0.1946, -1.7326],\n",
       "        [-0.2036, -1.6917],\n",
       "        [-0.1866, -1.7706],\n",
       "        [-0.8918, -0.5275],\n",
       "        [-1.0487, -0.4314],\n",
       "        [-1.1027, -0.4034],\n",
       "        [-0.1823, -1.7917],\n",
       "        [-1.4367, -0.2714],\n",
       "        [-1.0524, -0.4294]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj = next(iter(train_loader))\n",
    "model(jj[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a01664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_loader,test_loader,path,RESUME=False):\n",
    "    model=CustomModel()\n",
    "#     optimizer = getattr(torch.optim, CFG.optimizer)(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#                                                     lr=0.001,weight_decay=0.0001)  # 优化器\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = CFG.lr,weight_decay = CFG.weight_decay)\n",
    "#     scheduler = getattr(torch.optim.lr_scheduler, CFG.scheduler)(optimizer, gamma=CFG.sc_Gamma)  # 指数型学习率\n",
    "    lsrloss = LSR(CFG.num_classes,0.05)\n",
    "    start_epoch=-1\n",
    "    if RESUME:\n",
    "        path_checkpoint = path+'/ckpt_aml.pth'   # 断点路径\n",
    "        checkpoint = torch.load(path_checkpoint)  # 加载断点\n",
    "        model.load_state_dict(checkpoint['net'])  # 加载模型可学习参数\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])  # 加载优化器参数\n",
    "        start_epoch = checkpoint['epoch']  # 设置开始的epoch\n",
    "        #scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "#     batch_iterator = zip(loop_iterable(train_loader_sample), \n",
    "#                      loop_iterable(train_loader_batch))\n",
    "#     n_batches = max(len(train_loader_sample), len(train_loader_batch))\n",
    "\n",
    "    for epoch in range(start_epoch+1,CFG.epoches):\n",
    "        for data in train_loader:\n",
    "            input_feature = data[\"input\"]\n",
    "            true_label = data[\"label\"]\n",
    "            pred_label = model(input_feature)\n",
    "            loss=lsrloss(pred_label,true_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loss_sum = 0\n",
    "            for test_data in test_loader:\n",
    "                input_feature_test = test_data[\"input\"]\n",
    "                true_label_test = test_data[\"label\"]\n",
    "                pred_label_test = model(input_feature_test)\n",
    "                val_loss=lsrloss(pred_label_test,true_label_test)\n",
    "\n",
    "                val_loss_sum += val_loss\n",
    "            val_loss_mean = val_loss_sum/(len(test_loader))\n",
    "        #print(shot_RUL[0:10],RUL_pred_val[0:10])\n",
    "\n",
    "                \n",
    "        if  epoch % 20 == 0:\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()},val_loss:{val_loss_mean.item()}\")#,lr:{optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "            checkpoint = {\n",
    "                \"net\": model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                #'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            if not os.path.isdir(path):\n",
    "                os.mkdir(path)\n",
    "            torch.save(checkpoint,\n",
    "                       path+'/ckpt_aml.pth')\n",
    "#         if val_loss_mean.item() < 1600:\n",
    "#             print(f\"epoch:{epoch}, loss:{loss.item()},val_loss:{val_loss_mean.item()}\")      \n",
    "#                   #lr:{optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "#             save_model_weights(model, \"model_his_aml.pt\",\n",
    "#                                cp_folder=path)\n",
    "#             break\n",
    "        elif epoch == (CFG.epoches-1):\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()}\",)\n",
    "            save_model_weights(model, \"model_his_aml.pt\",\n",
    "                               cp_folder=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e11447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:0.7185090780258179,val_loss:0.6831567287445068\n",
      "epoch:20, loss:0.3153533339500427,val_loss:0.2991580665111542\n",
      "epoch:40, loss:0.2304818332195282,val_loss:0.2352849245071411\n",
      "epoch:60, loss:0.21511027216911316,val_loss:0.21655400097370148\n",
      "epoch:80, loss:0.21765132248401642,val_loss:0.20905137062072754\n",
      "epoch:100, loss:0.20517262816429138,val_loss:0.20562972128391266\n",
      "epoch:120, loss:0.2072899043560028,val_loss:0.2037397176027298\n",
      "epoch:140, loss:0.2053045779466629,val_loss:0.20265112817287445\n",
      "epoch:160, loss:0.20664076507091522,val_loss:0.20201390981674194\n",
      "epoch:180, loss:0.205412819981575,val_loss:0.2015949934720993\n",
      "epoch:199, loss:0.20561985671520233\n",
      "\n",
      " -> Saving weights to ./checkpoints\\model_his_aml.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_model(train_loader,test_loader,\"./checkpoints\",RESUME=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ae5df",
   "metadata": {},
   "source": [
    "# 模型的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ff0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_model=CustomModel()\n",
    "aml_model.load_state_dict(torch.load(\"./checkpoints/model_his_aml.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e67bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4714b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.exp(aml_model(test_[\"input\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e84b6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0415, 0.9585],\n",
       "         [0.0627, 0.9373],\n",
       "         [0.0567, 0.9433],\n",
       "         [0.9474, 0.0526],\n",
       "         [0.9159, 0.0841],\n",
       "         [0.0304, 0.9696]], grad_fn=<ExpBackward0>),\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,test_[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bb6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
